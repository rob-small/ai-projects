{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Regression Problem solved using dense layers in a DNN design\n",
    "Single run, no cross-validation\n",
    "Configured with Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust output directory for each run\n",
    "tensorboard = TensorBoard(log_dir = 'logs/regex/6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataframe = pandas.read_csv(\"housing.data\", delim_whitespace=True, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.sample(frac=1)\n",
    "dataset = dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:13]\n",
    "Y = dataset[:,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = 500\n",
    "x_train = X[:training_size]\n",
    "y_train = Y[:training_size]\n",
    "x_test = X[training_size:]\n",
    "y_test = Y[training_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=13, kernel_initializer='glorot_normal', activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "# Compile model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 128)               1792      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,921\n",
      "Trainable params: 1,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500 samples, validate on 6 samples\n",
      "Epoch 1/200\n",
      "500/500 [==============================] - 0s - loss: 4904.8926 - val_loss: 2245.3564\n",
      "Epoch 2/200\n",
      "500/500 [==============================] - 0s - loss: 2450.0693 - val_loss: 848.1631\n",
      "Epoch 3/200\n",
      "500/500 [==============================] - 0s - loss: 995.5823 - val_loss: 173.9208\n",
      "Epoch 4/200\n",
      "500/500 [==============================] - 0s - loss: 369.7997 - val_loss: 48.3386\n",
      "Epoch 5/200\n",
      "500/500 [==============================] - 0s - loss: 318.9621 - val_loss: 158.9817\n",
      "Epoch 6/200\n",
      "500/500 [==============================] - 0s - loss: 443.0436 - val_loss: 232.6461\n",
      "Epoch 7/200\n",
      "500/500 [==============================] - 0s - loss: 436.9954 - val_loss: 201.0062\n",
      "Epoch 8/200\n",
      "500/500 [==============================] - 0s - loss: 396.5233 - val_loss: 114.2045\n",
      "Epoch 9/200\n",
      "500/500 [==============================] - 0s - loss: 300.8345 - val_loss: 51.7374\n",
      "Epoch 10/200\n",
      "500/500 [==============================] - 0s - loss: 237.3030 - val_loss: 28.6259\n",
      "Epoch 11/200\n",
      "500/500 [==============================] - 0s - loss: 277.4688 - val_loss: 27.9417\n",
      "Epoch 12/200\n",
      "500/500 [==============================] - 0s - loss: 251.2019 - val_loss: 29.7926\n",
      "Epoch 13/200\n",
      "500/500 [==============================] - 0s - loss: 265.7355 - val_loss: 27.2987\n",
      "Epoch 14/200\n",
      "500/500 [==============================] - 0s - loss: 253.6588 - val_loss: 23.7555\n",
      "Epoch 15/200\n",
      "500/500 [==============================] - 0s - loss: 255.5184 - val_loss: 23.9418\n",
      "Epoch 16/200\n",
      "500/500 [==============================] - 0s - loss: 230.8673 - val_loss: 27.0577\n",
      "Epoch 17/200\n",
      "500/500 [==============================] - 0s - loss: 218.1211 - val_loss: 29.8167\n",
      "Epoch 18/200\n",
      "500/500 [==============================] - 0s - loss: 198.2872 - val_loss: 29.8450\n",
      "Epoch 19/200\n",
      "500/500 [==============================] - 0s - loss: 224.4852 - val_loss: 27.5590\n",
      "Epoch 20/200\n",
      "500/500 [==============================] - 0s - loss: 206.9093 - val_loss: 24.9433\n",
      "Epoch 21/200\n",
      "500/500 [==============================] - 0s - loss: 204.9314 - val_loss: 23.7716\n",
      "Epoch 22/200\n",
      "500/500 [==============================] - 0s - loss: 195.0249 - val_loss: 24.4631\n",
      "Epoch 23/200\n",
      "500/500 [==============================] - 0s - loss: 190.3277 - val_loss: 26.7753\n",
      "Epoch 24/200\n",
      "500/500 [==============================] - 0s - loss: 200.6396 - val_loss: 27.4625\n",
      "Epoch 25/200\n",
      "500/500 [==============================] - 0s - loss: 204.0595 - val_loss: 27.3881\n",
      "Epoch 26/200\n",
      "500/500 [==============================] - 0s - loss: 197.6408 - val_loss: 25.8099\n",
      "Epoch 27/200\n",
      "500/500 [==============================] - 0s - loss: 194.8751 - val_loss: 25.6164\n",
      "Epoch 28/200\n",
      "500/500 [==============================] - 0s - loss: 187.5287 - val_loss: 24.9380\n",
      "Epoch 29/200\n",
      "500/500 [==============================] - 0s - loss: 188.9291 - val_loss: 23.8934\n",
      "Epoch 30/200\n",
      "500/500 [==============================] - 0s - loss: 198.9742 - val_loss: 23.9231\n",
      "Epoch 31/200\n",
      "500/500 [==============================] - 0s - loss: 184.6860 - val_loss: 24.5167\n",
      "Epoch 32/200\n",
      "500/500 [==============================] - 0s - loss: 170.0402 - val_loss: 26.0431\n",
      "Epoch 33/200\n",
      "500/500 [==============================] - 0s - loss: 171.7660 - val_loss: 27.4324\n",
      "Epoch 34/200\n",
      "500/500 [==============================] - 0s - loss: 163.7173 - val_loss: 27.2453\n",
      "Epoch 35/200\n",
      "500/500 [==============================] - 0s - loss: 188.2573 - val_loss: 26.7435\n",
      "Epoch 36/200\n",
      "500/500 [==============================] - 0s - loss: 165.0340 - val_loss: 27.1800\n",
      "Epoch 37/200\n",
      "500/500 [==============================] - 0s - loss: 173.7436 - val_loss: 28.4086\n",
      "Epoch 38/200\n",
      "500/500 [==============================] - 0s - loss: 172.7636 - val_loss: 31.2316\n",
      "Epoch 39/200\n",
      "500/500 [==============================] - 0s - loss: 160.3843 - val_loss: 33.1236\n",
      "Epoch 40/200\n",
      "500/500 [==============================] - 0s - loss: 158.2927 - val_loss: 35.3239\n",
      "Epoch 41/200\n",
      "500/500 [==============================] - 0s - loss: 151.4151 - val_loss: 34.3547\n",
      "Epoch 42/200\n",
      "500/500 [==============================] - 0s - loss: 164.3245 - val_loss: 31.1260\n",
      "Epoch 43/200\n",
      "500/500 [==============================] - 0s - loss: 153.3180 - val_loss: 26.8323\n",
      "Epoch 44/200\n",
      "500/500 [==============================] - 0s - loss: 150.2339 - val_loss: 24.2157\n",
      "Epoch 45/200\n",
      "500/500 [==============================] - 0s - loss: 161.6994 - val_loss: 24.5065\n",
      "Epoch 46/200\n",
      "500/500 [==============================] - 0s - loss: 141.9944 - val_loss: 25.1029\n",
      "Epoch 47/200\n",
      "500/500 [==============================] - 0s - loss: 137.1713 - val_loss: 25.5448\n",
      "Epoch 48/200\n",
      "500/500 [==============================] - 0s - loss: 146.7093 - val_loss: 27.0972\n",
      "Epoch 49/200\n",
      "500/500 [==============================] - 0s - loss: 136.1430 - val_loss: 28.1772\n",
      "Epoch 50/200\n",
      "500/500 [==============================] - 0s - loss: 141.1186 - val_loss: 28.6764\n",
      "Epoch 51/200\n",
      "500/500 [==============================] - 0s - loss: 137.2938 - val_loss: 27.9837\n",
      "Epoch 52/200\n",
      "500/500 [==============================] - 0s - loss: 146.2254 - val_loss: 28.1957\n",
      "Epoch 53/200\n",
      "500/500 [==============================] - 0s - loss: 149.4125 - val_loss: 26.9474\n",
      "Epoch 54/200\n",
      "500/500 [==============================] - 0s - loss: 130.6296 - val_loss: 27.3861\n",
      "Epoch 55/200\n",
      "500/500 [==============================] - 0s - loss: 122.5549 - val_loss: 27.9699\n",
      "Epoch 56/200\n",
      "500/500 [==============================] - 0s - loss: 129.3903 - val_loss: 28.2984\n",
      "Epoch 57/200\n",
      "500/500 [==============================] - 0s - loss: 125.7197 - val_loss: 29.8137\n",
      "Epoch 58/200\n",
      "500/500 [==============================] - 0s - loss: 126.7198 - val_loss: 29.4749\n",
      "Epoch 59/200\n",
      "500/500 [==============================] - 0s - loss: 124.9990 - val_loss: 27.4073\n",
      "Epoch 60/200\n",
      "500/500 [==============================] - 0s - loss: 130.0466 - val_loss: 24.7462\n",
      "Epoch 61/200\n",
      "500/500 [==============================] - 0s - loss: 129.7234 - val_loss: 23.3236\n",
      "Epoch 62/200\n",
      "500/500 [==============================] - 0s - loss: 123.2846 - val_loss: 24.8047\n",
      "Epoch 63/200\n",
      "500/500 [==============================] - 0s - loss: 115.0865 - val_loss: 27.0537\n",
      "Epoch 64/200\n",
      "500/500 [==============================] - 0s - loss: 135.5204 - val_loss: 26.8673\n",
      "Epoch 65/200\n",
      "500/500 [==============================] - 0s - loss: 126.5203 - val_loss: 27.8885\n",
      "Epoch 66/200\n",
      "500/500 [==============================] - 0s - loss: 113.8119 - val_loss: 25.7656\n",
      "Epoch 67/200\n",
      "500/500 [==============================] - 0s - loss: 116.9386 - val_loss: 22.8552\n",
      "Epoch 68/200\n",
      "500/500 [==============================] - 0s - loss: 120.2070 - val_loss: 22.6758\n",
      "Epoch 69/200\n",
      "500/500 [==============================] - 0s - loss: 116.2151 - val_loss: 22.4716\n",
      "Epoch 70/200\n",
      "500/500 [==============================] - 0s - loss: 109.4147 - val_loss: 25.2055\n",
      "Epoch 71/200\n",
      "500/500 [==============================] - 0s - loss: 121.6861 - val_loss: 25.4399\n",
      "Epoch 72/200\n",
      "500/500 [==============================] - 0s - loss: 110.6747 - val_loss: 26.6272\n",
      "Epoch 73/200\n",
      "500/500 [==============================] - 0s - loss: 115.0866 - val_loss: 27.9848\n",
      "Epoch 74/200\n",
      "500/500 [==============================] - 0s - loss: 111.9110 - val_loss: 26.9217\n",
      "Epoch 75/200\n",
      "500/500 [==============================] - 0s - loss: 105.1858 - val_loss: 25.1008\n",
      "Epoch 76/200\n",
      "500/500 [==============================] - 0s - loss: 115.9412 - val_loss: 23.6059\n",
      "Epoch 77/200\n",
      "500/500 [==============================] - 0s - loss: 100.4025 - val_loss: 23.9870\n",
      "Epoch 78/200\n",
      "500/500 [==============================] - 0s - loss: 102.7737 - val_loss: 25.7728\n",
      "Epoch 79/200\n",
      "500/500 [==============================] - 0s - loss: 112.8749 - val_loss: 27.7904\n",
      "Epoch 80/200\n",
      "500/500 [==============================] - 0s - loss: 104.5790 - val_loss: 26.8636\n",
      "Epoch 81/200\n",
      "500/500 [==============================] - 0s - loss: 105.0913 - val_loss: 26.4464\n",
      "Epoch 82/200\n",
      "500/500 [==============================] - 0s - loss: 94.1763 - val_loss: 27.3550\n",
      "Epoch 83/200\n",
      "500/500 [==============================] - 0s - loss: 91.7441 - val_loss: 27.5172\n",
      "Epoch 84/200\n",
      "500/500 [==============================] - 0s - loss: 95.0601 - val_loss: 25.3066\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s - loss: 88.5949 - val_loss: 22.8646\n",
      "Epoch 86/200\n",
      "500/500 [==============================] - 0s - loss: 88.5823 - val_loss: 22.7272\n",
      "Epoch 87/200\n",
      "500/500 [==============================] - 0s - loss: 102.6192 - val_loss: 24.3661\n",
      "Epoch 88/200\n",
      "500/500 [==============================] - 0s - loss: 99.5416 - val_loss: 25.6224\n",
      "Epoch 89/200\n",
      "500/500 [==============================] - 0s - loss: 99.4483 - val_loss: 26.5272\n",
      "Epoch 90/200\n",
      "500/500 [==============================] - 0s - loss: 92.4755 - val_loss: 24.5364\n",
      "Epoch 91/200\n",
      "500/500 [==============================] - 0s - loss: 95.2310 - val_loss: 23.7113\n",
      "Epoch 92/200\n",
      "500/500 [==============================] - 0s - loss: 93.2110 - val_loss: 23.9695\n",
      "Epoch 93/200\n",
      "500/500 [==============================] - 0s - loss: 87.2795 - val_loss: 22.4868\n",
      "Epoch 94/200\n",
      "500/500 [==============================] - 0s - loss: 88.9493 - val_loss: 21.1484\n",
      "Epoch 95/200\n",
      "500/500 [==============================] - 0s - loss: 92.5958 - val_loss: 22.6568\n",
      "Epoch 96/200\n",
      "500/500 [==============================] - 0s - loss: 88.4329 - val_loss: 23.3177\n",
      "Epoch 97/200\n",
      "500/500 [==============================] - 0s - loss: 95.6348 - val_loss: 23.2110\n",
      "Epoch 98/200\n",
      "500/500 [==============================] - 0s - loss: 82.9146 - val_loss: 20.9402\n",
      "Epoch 99/200\n",
      "500/500 [==============================] - 0s - loss: 85.0508 - val_loss: 20.8520\n",
      "Epoch 100/200\n",
      "500/500 [==============================] - 0s - loss: 90.8229 - val_loss: 22.9831\n",
      "Epoch 101/200\n",
      "500/500 [==============================] - 0s - loss: 85.5641 - val_loss: 24.9221\n",
      "Epoch 102/200\n",
      "500/500 [==============================] - 0s - loss: 82.8726 - val_loss: 26.2115\n",
      "Epoch 103/200\n",
      "500/500 [==============================] - 0s - loss: 84.9164 - val_loss: 23.5135\n",
      "Epoch 104/200\n",
      "500/500 [==============================] - 0s - loss: 87.2518 - val_loss: 21.9217\n",
      "Epoch 105/200\n",
      "500/500 [==============================] - 0s - loss: 85.2164 - val_loss: 21.2616\n",
      "Epoch 106/200\n",
      "500/500 [==============================] - 0s - loss: 76.9260 - val_loss: 22.8842\n",
      "Epoch 107/200\n",
      "500/500 [==============================] - 0s - loss: 84.6192 - val_loss: 23.9612\n",
      "Epoch 108/200\n",
      "500/500 [==============================] - 0s - loss: 78.6802 - val_loss: 23.9306\n",
      "Epoch 109/200\n",
      "500/500 [==============================] - 0s - loss: 77.3645 - val_loss: 20.5789\n",
      "Epoch 110/200\n",
      "500/500 [==============================] - 0s - loss: 84.6750 - val_loss: 20.5144\n",
      "Epoch 111/200\n",
      "500/500 [==============================] - 0s - loss: 77.8768 - val_loss: 21.4675\n",
      "Epoch 112/200\n",
      "500/500 [==============================] - 0s - loss: 75.7460 - val_loss: 22.5156\n",
      "Epoch 113/200\n",
      "500/500 [==============================] - 0s - loss: 86.8790 - val_loss: 21.9753\n",
      "Epoch 114/200\n",
      "500/500 [==============================] - 0s - loss: 75.6948 - val_loss: 20.9589\n",
      "Epoch 115/200\n",
      "500/500 [==============================] - 0s - loss: 72.4262 - val_loss: 22.5359\n",
      "Epoch 116/200\n",
      "500/500 [==============================] - 0s - loss: 72.8441 - val_loss: 23.9801\n",
      "Epoch 117/200\n",
      "500/500 [==============================] - 0s - loss: 74.4101 - val_loss: 22.5868\n",
      "Epoch 118/200\n",
      "500/500 [==============================] - 0s - loss: 80.2546 - val_loss: 22.8819\n",
      "Epoch 119/200\n",
      "500/500 [==============================] - 0s - loss: 80.1594 - val_loss: 23.5338\n",
      "Epoch 120/200\n",
      "500/500 [==============================] - 0s - loss: 67.8384 - val_loss: 23.5183\n",
      "Epoch 121/200\n",
      "500/500 [==============================] - 0s - loss: 72.3916 - val_loss: 22.7947\n",
      "Epoch 122/200\n",
      "500/500 [==============================] - 0s - loss: 73.1738 - val_loss: 21.3431\n",
      "Epoch 123/200\n",
      "500/500 [==============================] - 0s - loss: 69.1075 - val_loss: 21.7142\n",
      "Epoch 124/200\n",
      "500/500 [==============================] - 0s - loss: 73.4959 - val_loss: 20.4808\n",
      "Epoch 125/200\n",
      "500/500 [==============================] - 0s - loss: 80.8302 - val_loss: 19.7400\n",
      "Epoch 126/200\n",
      "500/500 [==============================] - 0s - loss: 70.7052 - val_loss: 21.8904\n",
      "Epoch 127/200\n",
      "500/500 [==============================] - 0s - loss: 70.9941 - val_loss: 22.4922\n",
      "Epoch 128/200\n",
      "500/500 [==============================] - 0s - loss: 69.4089 - val_loss: 21.0397\n",
      "Epoch 129/200\n",
      "500/500 [==============================] - 0s - loss: 70.0527 - val_loss: 21.7575\n",
      "Epoch 130/200\n",
      "500/500 [==============================] - 0s - loss: 69.9583 - val_loss: 22.2930\n",
      "Epoch 131/200\n",
      "500/500 [==============================] - 0s - loss: 71.7367 - val_loss: 21.8479\n",
      "Epoch 132/200\n",
      "500/500 [==============================] - 0s - loss: 64.7752 - val_loss: 19.7407\n",
      "Epoch 133/200\n",
      "500/500 [==============================] - 0s - loss: 69.5665 - val_loss: 18.5961\n",
      "Epoch 134/200\n",
      "500/500 [==============================] - 0s - loss: 69.6031 - val_loss: 18.6596\n",
      "Epoch 135/200\n",
      "500/500 [==============================] - 0s - loss: 62.9129 - val_loss: 18.9356\n",
      "Epoch 136/200\n",
      "500/500 [==============================] - 0s - loss: 70.4283 - val_loss: 19.0281\n",
      "Epoch 137/200\n",
      "500/500 [==============================] - 0s - loss: 64.9104 - val_loss: 18.7260\n",
      "Epoch 138/200\n",
      "500/500 [==============================] - 0s - loss: 63.8932 - val_loss: 18.7303\n",
      "Epoch 139/200\n",
      "500/500 [==============================] - 0s - loss: 66.8726 - val_loss: 19.6772\n",
      "Epoch 140/200\n",
      "500/500 [==============================] - 0s - loss: 66.3867 - val_loss: 20.0880\n",
      "Epoch 141/200\n",
      "500/500 [==============================] - 0s - loss: 73.4798 - val_loss: 19.0179\n",
      "Epoch 142/200\n",
      "500/500 [==============================] - 0s - loss: 66.6957 - val_loss: 19.3278\n",
      "Epoch 143/200\n",
      "500/500 [==============================] - 0s - loss: 62.1958 - val_loss: 20.0809\n",
      "Epoch 144/200\n",
      "500/500 [==============================] - 0s - loss: 60.1166 - val_loss: 19.0447\n",
      "Epoch 145/200\n",
      "500/500 [==============================] - 0s - loss: 67.8914 - val_loss: 17.0910\n",
      "Epoch 146/200\n",
      "500/500 [==============================] - 0s - loss: 59.9575 - val_loss: 16.8873\n",
      "Epoch 147/200\n",
      "500/500 [==============================] - 0s - loss: 64.9915 - val_loss: 17.8104\n",
      "Epoch 148/200\n",
      "500/500 [==============================] - 0s - loss: 59.3175 - val_loss: 18.8018\n",
      "Epoch 149/200\n",
      "500/500 [==============================] - 0s - loss: 63.4484 - val_loss: 18.5241\n",
      "Epoch 150/200\n",
      "500/500 [==============================] - 0s - loss: 64.3405 - val_loss: 18.2119\n",
      "Epoch 151/200\n",
      "500/500 [==============================] - 0s - loss: 61.2241 - val_loss: 18.2406\n",
      "Epoch 152/200\n",
      "500/500 [==============================] - 0s - loss: 57.1102 - val_loss: 18.4690\n",
      "Epoch 153/200\n",
      "500/500 [==============================] - 0s - loss: 61.1886 - val_loss: 17.9494\n",
      "Epoch 154/200\n",
      "500/500 [==============================] - 0s - loss: 54.6782 - val_loss: 18.6458\n",
      "Epoch 155/200\n",
      "500/500 [==============================] - 0s - loss: 61.2836 - val_loss: 18.7997\n",
      "Epoch 156/200\n",
      "500/500 [==============================] - 0s - loss: 61.6518 - val_loss: 17.9113\n",
      "Epoch 157/200\n",
      "500/500 [==============================] - 0s - loss: 57.1731 - val_loss: 18.2311\n",
      "Epoch 158/200\n",
      "500/500 [==============================] - 0s - loss: 58.4291 - val_loss: 18.6303\n",
      "Epoch 159/200\n",
      "500/500 [==============================] - 0s - loss: 60.3171 - val_loss: 19.6780\n",
      "Epoch 160/200\n",
      "500/500 [==============================] - 0s - loss: 57.1362 - val_loss: 19.9788\n",
      "Epoch 161/200\n",
      "500/500 [==============================] - 0s - loss: 60.6690 - val_loss: 20.2092\n",
      "Epoch 162/200\n",
      "500/500 [==============================] - 0s - loss: 59.6863 - val_loss: 19.2195\n",
      "Epoch 163/200\n",
      "500/500 [==============================] - 0s - loss: 59.2158 - val_loss: 19.2591\n",
      "Epoch 164/200\n",
      "500/500 [==============================] - 0s - loss: 52.5102 - val_loss: 19.4986\n",
      "Epoch 165/200\n",
      "500/500 [==============================] - 0s - loss: 63.1954 - val_loss: 19.1959\n",
      "Epoch 166/200\n",
      "500/500 [==============================] - 0s - loss: 57.5009 - val_loss: 18.9709\n",
      "Epoch 167/200\n",
      "500/500 [==============================] - 0s - loss: 52.0111 - val_loss: 19.3493\n",
      "Epoch 168/200\n",
      "500/500 [==============================] - 0s - loss: 57.8604 - val_loss: 18.5411\n",
      "Epoch 169/200\n",
      "500/500 [==============================] - ETA: 0s - loss: 58.39 - 0s - loss: 60.4951 - val_loss: 18.7595\n",
      "Epoch 170/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s - loss: 57.1458 - val_loss: 19.0301\n",
      "Epoch 171/200\n",
      "500/500 [==============================] - 0s - loss: 52.3821 - val_loss: 18.7822\n",
      "Epoch 172/200\n",
      "500/500 [==============================] - 0s - loss: 52.9861 - val_loss: 18.2903\n",
      "Epoch 173/200\n",
      "500/500 [==============================] - 0s - loss: 52.5856 - val_loss: 18.7427\n",
      "Epoch 174/200\n",
      "500/500 [==============================] - 0s - loss: 57.6054 - val_loss: 19.8214\n",
      "Epoch 175/200\n",
      "500/500 [==============================] - 0s - loss: 55.4881 - val_loss: 18.3491\n",
      "Epoch 176/200\n",
      "500/500 [==============================] - 0s - loss: 56.9614 - val_loss: 17.6452\n",
      "Epoch 177/200\n",
      "500/500 [==============================] - 0s - loss: 53.1958 - val_loss: 17.6426\n",
      "Epoch 178/200\n",
      "500/500 [==============================] - 0s - loss: 56.3676 - val_loss: 17.4268\n",
      "Epoch 179/200\n",
      "500/500 [==============================] - 0s - loss: 54.1700 - val_loss: 16.5249\n",
      "Epoch 180/200\n",
      "500/500 [==============================] - 0s - loss: 53.9310 - val_loss: 16.7784\n",
      "Epoch 181/200\n",
      "500/500 [==============================] - 0s - loss: 51.0265 - val_loss: 17.7765\n",
      "Epoch 182/200\n",
      "500/500 [==============================] - 0s - loss: 52.0500 - val_loss: 18.7529\n",
      "Epoch 183/200\n",
      "500/500 [==============================] - 0s - loss: 52.0336 - val_loss: 18.3112\n",
      "Epoch 184/200\n",
      "500/500 [==============================] - 0s - loss: 52.9701 - val_loss: 17.7222\n",
      "Epoch 185/200\n",
      "500/500 [==============================] - 0s - loss: 48.6261 - val_loss: 18.1031\n",
      "Epoch 186/200\n",
      "500/500 [==============================] - 0s - loss: 54.3112 - val_loss: 17.1891\n",
      "Epoch 187/200\n",
      "500/500 [==============================] - 0s - loss: 49.1569 - val_loss: 17.2402\n",
      "Epoch 188/200\n",
      "500/500 [==============================] - 0s - loss: 54.7094 - val_loss: 17.7362\n",
      "Epoch 189/200\n",
      "500/500 [==============================] - 0s - loss: 49.2647 - val_loss: 17.7492\n",
      "Epoch 190/200\n",
      "500/500 [==============================] - 0s - loss: 50.5937 - val_loss: 17.6868\n",
      "Epoch 191/200\n",
      "500/500 [==============================] - 0s - loss: 47.6580 - val_loss: 17.8071\n",
      "Epoch 192/200\n",
      "500/500 [==============================] - 0s - loss: 46.6754 - val_loss: 17.5509\n",
      "Epoch 193/200\n",
      "500/500 [==============================] - 0s - loss: 45.5396 - val_loss: 17.4811\n",
      "Epoch 194/200\n",
      "500/500 [==============================] - 0s - loss: 49.6929 - val_loss: 17.2673\n",
      "Epoch 195/200\n",
      "500/500 [==============================] - 0s - loss: 50.1321 - val_loss: 16.8976\n",
      "Epoch 196/200\n",
      "500/500 [==============================] - 0s - loss: 48.6850 - val_loss: 16.8204\n",
      "Epoch 197/200\n",
      "500/500 [==============================] - 0s - loss: 47.0493 - val_loss: 16.8674\n",
      "Epoch 198/200\n",
      "500/500 [==============================] - 0s - loss: 51.4442 - val_loss: 16.5503\n",
      "Epoch 199/200\n",
      "500/500 [==============================] - 0s - loss: 45.4441 - val_loss: 15.8077\n",
      "Epoch 200/200\n",
      "500/500 [==============================] - 0s - loss: 48.1865 - val_loss: 15.5396\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fda7c1fe550>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=128, epochs=200, verbose=1, validation_data=(x_test, y_test),callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
