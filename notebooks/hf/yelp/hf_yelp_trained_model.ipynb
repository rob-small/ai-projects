{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "as9-69qLb2fx"
   },
   "source": [
    "# Fine-tune a pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tNNkUBg4b2fy"
   },
   "source": [
    "There are significant benefits to using a pretrained model. It reduces computation costs, your carbon footprint, and allows you to use state-of-the-art models without having to train one from scratch. ðŸ¤— Transformers provides access to thousands of pretrained models for a wide range of tasks. When you use a pretrained model, you train it on a dataset specific to your task. This is known as fine-tuning, an incredibly powerful training technique. In this tutorial, you will fine-tune a pretrained model with a deep learning framework of your choice:\n",
    "\n",
    "* Fine-tune a pretrained model with ðŸ¤— Transformers [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer).\n",
    "* Fine-tune a pretrained model in native PyTorch.\n",
    "\n",
    "<a id='data-processing'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-UCwgY48b2fz"
   },
   "source": [
    "## Prepare a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jmwq12qxb2f0"
   },
   "source": [
    "Before you can fine-tune a pretrained model, download a dataset and prepare it for training. The previous tutorial showed you how to process data for training, and now you get an opportunity to put those skills to the test!\n",
    "\n",
    "Begin by loading the [Yelp Reviews](https://huggingface.co/datasets/yelp_review_full) dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "35V8jnc2b2f0",
    "outputId": "4a131c21-91c2-4dee-c48e-5cbce96bd49e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "35V8jnc2b2f0",
    "outputId": "4a131c21-91c2-4dee-c48e-5cbce96bd49e"
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"yelp_review_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 650000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "35V8jnc2b2f0",
    "outputId": "4a131c21-91c2-4dee-c48e-5cbce96bd49e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'text': \"Owning a driving range inside the city limits is like a license to print money.  I don't think I ask much out of a driving range.  Decent mats, clean balls and accessible hours.  Hell you need even less people now with the advent of the machine that doles out the balls.  This place has none of them.  It is april and there are no grass tees yet.  BTW they opened for the season this week although it has been golfing weather for a month.  The mats look like the carpet at my 107 year old aunt Irene's house.  Worn and thread bare.  Let's talk about the hours.  This place is equipped with lights yet they only sell buckets of balls until 730.  It is still light out.  Finally lets you have the pit to hit into.  When I arrived I wasn't sure if this was a driving range or an excavation site for a mastodon or a strip mining operation.  There is no grass on the range. Just mud.  Makes it a good tool to figure out how far you actually are hitting the ball.  Oh, they are cash only also.\\\\n\\\\nBottom line, this place sucks.  The best hope is that the owner sells it to someone that actually wants to make money and service golfers in Pittsburgh.\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': ClassLabel(names=['1 star', '2 star', '3 stars', '4 stars', '5 stars'], id=None),\n",
       " 'text': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"].features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mSn-A03mb2f1"
   },
   "source": [
    "As you now know, you need a tokenizer to process the text and include a padding and truncation strategy to handle any variable sequence lengths. To process your dataset in one step, use ðŸ¤— Datasets [`map`](https://huggingface.co/docs/datasets/process.html#map) method to apply a preprocessing function over the entire dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ur9Ee3d0b2f1"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ur9Ee3d0b2f1"
   },
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ur9Ee3d0b2f1"
   },
   "outputs": [],
   "source": [
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_cDbvJCb2f2"
   },
   "source": [
    "If you like, you can create a smaller subset of the full dataset to fine-tune on to reduce the time it takes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "r_cDbvJCb2f2"
   },
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))\n",
    "small_validation_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000,2000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0o_BFNzwb2f2"
   },
   "source": [
    "<a id='trainer'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrNYlcYob2f2"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6kiYttg7b2f3"
   },
   "source": [
    "At this point, you should follow the section corresponding to the framework you want to use. You can use the links\n",
    "in the right sidebar to jump to the one you want - and if you want to hide all of the content for a given framework,\n",
    "just use the button at the top-right of that framework's block!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpMRdNaJb2f3"
   },
   "source": [
    "## Train with PyTorch Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1DHnDcdnb2f3"
   },
   "source": [
    "ðŸ¤— Transformers provides a [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) class optimized for training ðŸ¤— Transformers models, making it easier to start training without manually writing your own training loop. The [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) API supports a wide range of training options and features such as logging, gradient accumulation, and mixed precision.\n",
    "\n",
    "Start by loading your model and specify the number of expected labels. From the Yelp Review [dataset card](https://huggingface.co/datasets/yelp_review_full#data-fields), you know there are five labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "WABoNXTVb2f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "WABoNXTVb2f3"
   },
   "outputs": [],
   "source": [
    "trained_model = AutoModelForSequenceClassification.from_pretrained(\"models/bert_base_cased/yelp\", num_labels=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mo0WvE4jb2f4"
   },
   "source": [
    "<Tip>\n",
    "\n",
    "You will see a warning about some of the pretrained weights not being used and some weights being randomly\n",
    "initialized. Don't worry, this is completely normal! The pretrained head of the BERT model is discarded, and replaced with a randomly initialized classification head. You will fine-tune this new model head on your sequence classification task, transferring the knowledge of the pretrained model to it.\n",
    "\n",
    "</Tip>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_ISL3Dmb2f4"
   },
   "source": [
    "### Training hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gbeIkMHb2f4"
   },
   "source": [
    "Next, create a [TrainingArguments](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments) class which contains all the hyperparameters you can tune as well as flags for activating different training options. For this tutorial you can start with the default training [hyperparameters](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments), but feel free to experiment with these to find your optimal settings.\n",
    "\n",
    "Specify where to save the checkpoints from your training:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nu8bItbIb2f4"
   },
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training_args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUDCWus0b2f4"
   },
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wru2feE0b2f4"
   },
   "source": [
    "[Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) does not automatically evaluate model performance during training. You'll need to pass [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) a function to compute and report metrics. The [ðŸ¤— Evaluate](https://huggingface.co/docs/evaluate/index) library provides a simple [`accuracy`](https://huggingface.co/spaces/evaluate-metric/accuracy) function you can load with the [evaluate.load](https://huggingface.co/docs/evaluate/main/en/package_reference/loading_methods#evaluate.load) (see this [quicktour](https://huggingface.co/docs/evaluate/a_quick_tour) for more information) function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6z3kpg58b2f4"
   },
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NIy_vv44b2f5"
   },
   "source": [
    "Call `compute` on `metric` to calculate the accuracy of your predictions. Before passing your predictions to `compute`, you need to convert the predictions to logits (remember all ðŸ¤— Transformers models return logits):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3H37uJrb2f5"
   },
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2yfs8AHGb2f5"
   },
   "source": [
    "If you'd like to monitor your evaluation metrics during fine-tuning, specify the `evaluation_strategy` parameter in your training arguments to report the evaluation metric at the end of each epoch:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74VoO3Jhb2f5"
   },
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-r9E8IsZb2f5"
   },
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTy0x_byb2f5"
   },
   "source": [
    "Create a [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) object with your model, training arguments, training and test datasets, and evaluation function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_AFRGV2Gb2f5"
   },
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8z0sb5VVb2f5"
   },
   "source": [
    "Then fine-tune your model by calling [train()](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.train):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ErCFmOXNb2f6"
   },
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trainer.save_model(\"models/bert_base_cased/yelp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenized_datasets.save_to_disk(\"data/yelp/tokenized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whZize2tb2gE"
   },
   "source": [
    "## Additional resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9ARXVhxb2gE"
   },
   "source": [
    "For more fine-tuning examples, refer to:\n",
    "\n",
    "- [ðŸ¤— Transformers Examples](https://github.com/huggingface/transformers/tree/main/examples) includes scripts\n",
    "  to train common NLP tasks in PyTorch and TensorFlow.\n",
    "\n",
    "- [ðŸ¤— Transformers Notebooks](https://huggingface.co/docs/transformers/main/en/notebooks) contains various notebooks on how to fine-tune a model for specific tasks in PyTorch and TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe_base = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=base_model,\n",
    "    batch_size=8,\n",
    "    tokenizer=tokenizer,\n",
    "    device=0,\n",
    "    top_k=1\n",
    ")\n",
    "\n",
    "pipe_trained = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=trained_model,\n",
    "    batch_size=8,\n",
    "    tokenizer=tokenizer,\n",
    "    device=0,\n",
    "    top_k=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review Text From the moment we were sat, we waited for almost 10 minutes to be greeted by our server.  The restaurant was empty by the way...we were the only poeple in there.  When we asked about the menu, we got the vaguest descriptions of the sushi rolls.  Being the only table In the restaurant, we were surprised that our order took extra long.  The server never came back and out drinks were not refilled.  Part of our order was finally delivered but our appetizer was not to be seen.  We were finally told that there was a problem in the kitchen and a few minutes later the appetizer and second roll arrived. You would think. Being the only table in the restaurant, everything would be perfect.  Not the case.  Maybe that is why they are so super slow for lunch?  We'll go back to RA next time. :(\n",
      "Model prediction (trained):  [[{'label': 'LABEL_0', 'score': 0.747056782245636}]]\n",
      "Model prediction (base) [[{'label': 'LABEL_3', 'score': 0.2621239125728607}]]\n",
      "Label  0\n",
      "Review Text I rode along with a friend to Scottsdale for the day and she treated me to lunch. We ended up going to Stingray Sushi near the Fashion Square Mall. They have a great patio to sit out on and enjoy a nice day in AZ. The sushi was good we got a Vegas roll a Philli roll and a California roll pretty standard and then a order of chicken yakitori. Between three of us it was plenty and our friend had plenty left over to take home which was good. The Vegas roll was mildly soggy from all the eel sauce when it got to us and the chicken was dry but it still tasted alright. The service was pretty good both times i have been. I would go if i was in the neighborhood and wanted sushi.\n",
      "Model prediction (trained):  [[{'label': 'LABEL_2', 'score': 0.7094016671180725}]]\n",
      "Model prediction (base) [[{'label': 'LABEL_0', 'score': 0.29336684942245483}]]\n",
      "Label  2\n",
      "Review Text ugh....well, let me start over. absolutely great music. beautiful people. but you will PAY! 15 bucks a drink (luckily we got pretty wasted on a case or two of supermarket beer before going over), so we only had one each. \\n\\nand it's the first time i've ever given the door man money to let us in a club. my wife and her friend...no problem. 2 hot chicks...but then i was the tagalong, so they wouldn't let me in with them. \\n\\nfinally got in and luckily didn't have to pay cover (you get bombarded with free passes up and down the strip) but once inside.....felt like i was a big baller. \\n\\nso maybe i should give it more stars but the freaking door man....in defense, i guess it was halloween weekend and this is after all Fity Cents club.\n",
      "Model prediction (trained):  [[{'label': 'LABEL_3', 'score': 0.5750151872634888}]]\n",
      "Model prediction (base) [[{'label': 'LABEL_3', 'score': 0.2650485932826996}]]\n",
      "Label  1\n",
      "Review Text I just bought a house and needed my doors re-locked.  Called around 9:30 and Toby was there by 1:00pm.  He was courteous, professional and knowledgeable.  Would definitely recommend him to anyone needing a great locksmith.\\nThanks!\n",
      "Model prediction (trained):  [[{'label': 'LABEL_4', 'score': 0.8199943900108337}]]\n",
      "Model prediction (base) [[{'label': 'LABEL_3', 'score': 0.2760075628757477}]]\n",
      "Label  4\n",
      "Review Text i visited on jan 19 and ordered the thai basil (their signature dish) with calamari, which had a very unique flavor that was a bit masked by the spiciness. i'm a wimp when it comes to spices, and i was overwhelmed by the medium i ordered. though the dish was very good, it was, for a dish dish consisting mostly of vegetables, on the scant side for 11.95. \\n\\nmy friend ordered a curry, and it was a sizable portion, presented in a clay pot. i sneaked a bite, and it was very good too.\\n\\nthe place is comfortable and intimate, with booths and tables, and the wait staff is very friendly.\n",
      "Model prediction (trained):  [[{'label': 'LABEL_3', 'score': 0.7909067273139954}]]\n",
      "Model prediction (base) [[{'label': 'LABEL_0', 'score': 0.2699466049671173}]]\n",
      "Label  2\n",
      "Review Text Had dinner last night.  I ordered calamari from our waiter who called himself \\\"meatball,\\\" and I  asked if he had tarter sauce.  He said they did not have tarter sauce. I asked if he had any mayo (I could make my own).  He said to me \\\"I'm not making you tarter sauce,\\\" then turned his head and mouthed some obscene remark.  I was very insulted.    After dinner I paid the bill and gave him a 10% tip instead of my standard 20% and on the check I added a message that he insulted me and I'd see him on Yelp.  He ran after me where I was standing at the curb, irrationally and aggressively talking about the tarter sauce.  I tried to explain that he totally missed the point, and that it was how he handled my request, but he wouldn't listen.  He told me to get off the  (public) property or he would call the police.  My husband thought \\\"meatball,\\\" a 350 pound guy, was going to hit me.  The whole scene was a nightmare.  This is the first time I have critiqued a restaurant on Yelp and I was astounded at the depth of the negative reviews.\n",
      "Model prediction (trained):  [[{'label': 'LABEL_0', 'score': 0.8914742469787598}]]\n",
      "Model prediction (base) [[{'label': 'LABEL_0', 'score': 0.28525376319885254}]]\n",
      "Label  0\n",
      "Review Text I was extremely excited to finally eat here! in the end.. I was very disappointed.\\n\\nMy boyfriend and I love oysters! Being an oyster bar we thought it must be fresh and delicious! Holy crap was the oysters shitty!  We could not believe how dirty the oysters were! They did not take the liberty to rinse or scrub the oysters shells before prying them open.  I do not think they were fresh! We bough a dozen and could barely finish half.. My boyfriend almost yacked up one of them because it was already bad.  It was already hard enough trying to eat the dirty oysters..after eating the bad one we noticed the couple others didn't look good.  The worker at the end never took our plate away until the end asking if we were going to finish it.. yeah we just said no.  There's something wrong there if we did not finish it buddy!  We watched them open the oysters after and saw how dirty the shells were and noticed that the shells had bands around them to keep the oysters from opening.  THIS PLACE IS NOT KNOWN FOR THE OYSTERS!\\n\\nWe also had New England Clam Chowder and Chicken Gumbo.  These came out a lot better.  I've never had Gumbo but my boyfriend said it was decently good.  I am a fan of clam chowder, and it was good, nothing amazing.  So the rest of the food must be the talk of the joint.\\n\\nThe service, it was mehhh.  I swear the cook in front of us looked miserable, took some time for us to have a server attend to us the couple times we needed something..\\n\\nDefinitely will not be back..\n",
      "Model prediction (trained):  [[{'label': 'LABEL_1', 'score': 0.7601374387741089}]]\n",
      "Model prediction (base) [[{'label': 'LABEL_0', 'score': 0.2827310860157013}]]\n",
      "Label  1\n",
      "Review Text This place is really amazing.  Everything about it was really great: service, ambiance, food, desert, drinks.  I had the soup, which is amazing.  I then had the deer medallions and the cheesecake to finish.  Everything tasted REALLY great and the prices were reasonable.  If you are in the area this is a MUST visit restaurant.\n",
      "Model prediction (trained):  [[{'label': 'LABEL_4', 'score': 0.7544708847999573}]]\n",
      "Model prediction (base) [[{'label': 'LABEL_3', 'score': 0.2691669762134552}]]\n",
      "Label  4\n",
      "Review Text Boneless Wings had a tasty sauce, but not enough sauce and too much coating for my taste.\n",
      "Model prediction (trained):  [[{'label': 'LABEL_2', 'score': 0.662854015827179}]]\n",
      "Model prediction (base) [[{'label': 'LABEL_3', 'score': 0.26791128516197205}]]\n",
      "Label  1\n",
      "Review Text Oh Lush how I love thee. I was fortunate to discover Lush in 2000 while traveling in Sweden. At that time I bought as much as I could fit into my backpack and brought it back to the States! Yes I was a Lush smuggler.Every time I returned to Europe I bought all the Lush products I could. I think since 2000 I have been to a Lush store in over 12 countries! Even Iceland had a store before the US did!\\nSince I was traveling a decent amount my favorite product was and still is their shampoo bars. They are great to pack since they don't take up much space and you don't have to worry about the liquid ban!\\n\\nOne negative thing is that Lush will discontinue items- including my favorite shampoo bar ever- Jumping Juniper =(\\n\\nThere is an amazing sale after Christmas where their poxed sets are buy 1 get 2 free!!!\\n\\nThe only reason I can't give the store 5 stars is the odor. Some people really like the smell in the store, but for me it is overpowering and I have to leave the store for a few min. while shopping in order to breathe. A larger store doesn't smell quite as strong as the FS store. I think more ventilation is in order. \\n\\nBut overall go forth and shop!\n",
      "Model prediction (trained):  [[{'label': 'LABEL_3', 'score': 0.553972065448761}]]\n",
      "Model prediction (base) [[{'label': 'LABEL_0', 'score': 0.2856830656528473}]]\n",
      "Label  3\n"
     ]
    }
   ],
   "source": [
    "for n in range(10,20):\n",
    "    print(\"Review Text\",small_validation_dataset[n][\"text\"])\n",
    "    print(\"Model prediction (trained): \", pipe_trained(small_validation_dataset[n][\"text\"]))\n",
    "    print(\"Model prediction (base)\", pipe_base(small_validation_dataset[n][\"text\"]))\n",
    "    print(\"Label \", small_validation_dataset[n][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Load a pretrained transformer model and tokenizer\n",
    "model_name = \"bert-base-uncased\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=4)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Log the model as an MLflow Model\n",
    "mlflow.set_experiment(\"multiclass_classifier\")\n",
    "with mlflow.start_run():\n",
    "  mlflow.log_param(\"model_name\", model_name)\n",
    "  mlflow.transformers.log_model(model, tokenizer, \"model\")\n",
    "\n",
    "# Load a test dataset with labels\n",
    "test_data = ... # load your test data here\n",
    "test_labels = ... # load your test labels here\n",
    "\n",
    "# Evaluate the model performance on the test dataset\n",
    "mlflow.evaluate(\"model\", test_data, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_validation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_validation_dataset[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/training.ipynb",
     "timestamp": 1700680154141
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
